#  Twitter Sentiment Analysis - Natural Language Processing

## ðŸ“Œ Overview

This project performs **sentiment analysis** on tweets, with a focus on detecting **hate speech** using Natural Language Processing (NLP) and supervised machine learning models. The analysis involves extensive **text preprocessing**, **feature extraction**, and **model training and evaluation** to classify tweets as hate speech or not.

---

## ðŸ“ Dataset

- **Source**: [Kaggle - Twitter Sentiment Analysis Dataset](https://www.kaggle.com/datasets)
- **Size**: 31,962 labeled tweets
- **Labels**:
  - `0` = Hate Speech
  - `1` = Offensive Language
  - `2` = Neither

---

## ðŸ§° Tools & Technologies

### ðŸ”¤ Text Preprocessing
- `NLTK`: Tokenization, stopword removal
- `TextBlob`: Word stemming
- `TF-IDF Vectorizer` and `Count Vectorizer`: Feature extraction

### ðŸ§  Machine Learning
- `Scikit-learn`: Model building and evaluation
- `XGBoost`, `LightGBM`: Gradient boosting classifiers
- `Logistic Regression`: Baseline model

### ðŸ“Š Visualization
- `Matplotlib`: Performance charts and insights

### ðŸ“š Data Manipulation
- `Pandas`, `NumPy`

---

## ðŸ§ª Project Workflow

1. **Data Loading**
   - Import dataset from Kaggle
   - Explore class balance and structure

2. **Text Preprocessing**
   - Lowercasing, punctuation removal
   - Tokenization and stopword removal using NLTK
   - Stemming using TextBlob
   - Feature engineering with CountVectorizer and TF-IDF

3. **Model Building**
   - Models trained:
     - Logistic Regression
     - LightGBM
     - XGBoost
   - Evaluated using ROC-AUC, accuracy, and confusion matrix

4. **Model Evaluation**
   - Selected best model (XGBoost) based on performance metrics

---

## ðŸ“ˆ Model Performance Summary

| Model               | Accuracy | ROC-AUC Score |
|--------------------|----------|---------------|
| Logistic Regression | 0.83     | 0.85          |
| LightGBM            | 0.86     | 0.88          |
| XGBoost             | 0.88     | 0.89 âœ…        |

> âœ… **XGBoost** performed the best overall and was selected for final deployment/testing.

---

## ðŸ“Š Dashboard & Visualizations

The project includes the following visual outputs:
- Confusion matrix
- Feature importance plot
- ROC curves
- Class distribution bar chart

---
Hereâ€™s an improved and **cleaned-up** version of the **Project Structure** and **How to Run** sections with:

* Better formatting
* Clearer descriptions
* Corrected code block syntax
* Removed unnecessary backslashes in filenames

---

## ðŸ—‚ï¸ Project Structure

```text
twitter-sentiment-analysis/
â”œâ”€â”€ data/                         # Contains the original dataset
â”‚   â””â”€â”€ tweets.csv
â”œâ”€â”€ notebooks/                    # Step-by-step Jupyter Notebooks
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb       # Data loading and initial analysis
â”‚   â”œâ”€â”€ 02_text_preprocessing.ipynb     # Tokenization, stopword removal, stemming
â”‚   â”œâ”€â”€ 03_feature_engineering.ipynb    # Vectorization using TF-IDF & CountVectorizer
â”‚   â”œâ”€â”€ 04_model_training.ipynb         # ML model implementation and training
â”‚   â””â”€â”€ 05_evaluation.ipynb             # Model performance evaluation
â”œâ”€â”€ models/                      # Trained and saved models
â”‚   â””â”€â”€ final_model_xgboost.pkl
â”œâ”€â”€ images/                      # Visualization outputs (ROC curves, confusion matrix, etc.)
â”‚   â””â”€â”€ confusion_matrix.png
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ LICENSE                      # MIT License file
â””â”€â”€ README.md                    # Project documentation
```

---

##  How to Run

Follow the steps below to set up and run the project locally:

1. **Clone the repository:**

   ```bash
   git clone https://github.com/your-username/twitter-sentiment-analysis.git
   cd twitter-sentiment-analysis
   ```

2. **Install dependencies:**

   ```bash
   pip install -r requirements.txt
   ```

3. **Launch the notebooks:**

   Open the `.ipynb` files in the `notebooks/` folder using **Jupyter Notebook** or **JupyterLab**, and run them in the following order:

   1. `01_data_exploration.ipynb`
   2. `02_text_preprocessing.ipynb`
   3. `03_feature_engineering.ipynb`
   4. `04_model_training.ipynb`
   5. `05_evaluation.ipynb`

> âœ… Ensure Python 3.7+ is installed and compatible versions of required packages are used.

---


## ðŸ“„ License

This project is licensed under the **MIT License**.
See the [LICENSE](LICENSE) file for more details.

---

---

##  Acknowledgments

* Kaggle for the dataset
* NLTK, TextBlob, Scikit-learn, LightGBM, and XGBoost for their powerful libraries
* Open-source contributors and the data science community

```


